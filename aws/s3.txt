#=======================
# Host a Static Website
#=======================
Services -> S3
Create 2 buckets:
    'Create bucket' -> nakeddomain.com
    'Create bucket' -> www.domain.com
Bucket -> Properties -> Static Website Hosting
Redict the naked domain to www. (nakeddomain.com)
Use bucket to host a website (www.domain.com):
    choose index.html page
    choose error.html page
Bucket -> Permissions -> Untick 'Block all public access' -> 'Save'
Update bucket policy to allow for web access

#=====================
# Host React App on S3
#=====================
- create bucket
- unlock by removing bucket policy and acl lock
- Properties > Static Website Hosting > Enable
- Select index.html as entry point
- Permissions > Bucket policy (getObject)

On React
--------
npm build - builds the project
Copy contents of build folder on to bucket 
aws s3 sync path/to/local/build/ s3://bucket_name
 


#=======
# S3 CLI
#=======

# List all buckets
aws s3 ls
aws s3api list-buckets

# List contents of specific bucket
aws s3 ls s3://bucket_name/

# Create a new bucket
aws s3 mb --region eu-west-1 s3://bucket_name
aws s3api create-bucket --bucket my-bucket-name --region eu-west-1

# Enable versioning
aws s3api put-bucket-versioning \
--bucket <bucket_name> \
--versioning-configuration Status=Enabled

# Copy a file from local to s3
aws s3 cp my-file.txt s3://bucket_name

# Copy file(s) from S3 to local current directory
aws s3 cp s3://<bucket-name>/ . --recursive

# Copy large number of files into s3
aws s3 sync path/to/directory s3//bucket_name

# Turn bucket into Static Website
aws s3 website s3://example.org --index-document index.html --error-document error.html

# Copy docs/dirs in current directory into s3 bucket used as website
aws s3 cp . s3://<bucket-name>/ --recursive --acl public-read

# Generate a presigned url
aws s3 presign s3://mybucket/myobject --expires-in 3600 --region my-region

# List files inside an S3 bucket
aws s3 ls <bucket-name>

# Sync files in s3 bucket & prefix to the current local directory
aws s3 sync path/to/dir s3://mybucket/myprefix

# Remove object from bucket
aws s3 rm s3://mybucket/myprefix/file.txt

# Get objet versions
aws s3api list-object-versions \
--bucket <bucket-name> \
--prefix folder/file_name.txt

# Associate bucket notification to bucket
aws s3api put-bucket-notification-configuration \
--bucket <bucket-name> \
--notification-configuration file://s3EventNotification.json

# Add object to s3 
aws s3api put-object \
--bucket <bucket-name> \
--key bucket-folder/object_name.jpg \
--body ~/local/path/to/object_name.jpg


#=========
# boto3
#==========


import boto3
s3 = boto3.client('s3')

# Upload files
with open('filename', 'rb') as data:
    s3.upload_fileobj(data, 'mybucket', 'mykey')


#======================
# Mount a bucket to ec2
#======================

# Update OS
(RHEL/AMAZON Linux 2) yum update -y
(Debian/Ubuntu) apt update

# Install dependancies for fuse and s3cmd
(RHEL/AMAZON Linux 2) yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -y
(Debian/Ubuntu) sudo apt-get install automake autotools-dev fuse g++ git libcurl4-gnutls-dev libfuse-dev libssl-dev libxml2-dev make pkg-config -y

# Download s3fs
git clone https://github.com/s3fs-fuse/s3fs-fuse.git

# Compile and install
cd  s3fs-fuse
./autogen.sh 
./configure — prefix=/usr — with-openssl
make
sudo make install

# Check if s3fs installed
which s3fs

# Setup Access Key or Role (Connect EC2 to Role on console)
echo AWS_ACCESS_KEY_ID:AWS_SECRET_ACCESS_KEY > ~/.passwd-s3fs
chmod 755 ~/.passwd-s3fs

# Create Mount script (.sh)
s3fs -o iam_role="<role-name>" \
-o url="https://s3-eu-west-1.amazonaws.com" \
-o endpoint=eu-west-1 \
-o dbglevel=info \
-o <bucket-name> <path/to/mount>

# Give script execution rights
chmod +x <script_name.sh>



# Add path to server fstab
crontab -e
